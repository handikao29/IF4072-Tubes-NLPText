{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP (Text) Assignment\n",
    "\n",
    "Aspect Based Sentiment Analysis on Trip(?) Review\n",
    "\n",
    "by:\n",
    "- 13515035 - Oktavianus Handika\n",
    "- 13515075 - Adrian Mulyana Nugraha\n",
    "\n",
    "Used dataset: https://www.kaggle.com/anu0012/hotel-review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "#Read the train dataset from csv file\n",
    "train = pd.read_csv(\"dataset/train1.csv\", usecols=['Description','Is_Response'])\n",
    "test = pd.read_csv(\"dataset/test1.csv\", usecols=['Description'])\n",
    "array = np.array(train)\n",
    "array_test = np.array(test)\n",
    "X = array[:,:-1]\n",
    "y = array[:,-1]\n",
    "X_test = array[:,:-1]\n",
    "y_test = array[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Looking for a motel in close proximity to TV t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walking distance to Madison Square Garden and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Visited Seattle on business. Spent - nights in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This hotel location is excellent and the rooms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This hotel is awesome I love the service Antho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rooms, concierge services and party scene were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What a pleasant place to stay!\\nThe hotel is b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I booked out the same day I arrived. It cost m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Unlike some hotels that grimace when you show ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hotel Sorella for my birthday. I absolutely lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I had a very comfortable stay at Baymont. It w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This hotel is a keeper! First, you get a full ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Really nice lobby, with free coffee, water, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>There's a reason why so many of the previous r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Great location, close to Times Square and so m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>We booked the Hampton for one night based on T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I stayed here with my girlfriend who was atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>From the location to service to amenities, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>my work sent me down to jacksonville - times t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Stayed here for two nights while I visited DC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>This was my first visit to this property. To b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>We thoroughly enjoyed our stay here. Close to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Can't say enough about our recent stay at Hote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>There are experiences in life that you embrace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Reserved a King Suite at the Blackstone thinki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>This is not your typical Fairfield Inn archite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>This is the best place to stay in downtown Den...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>This is - min away from Times Square, Central ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Check in to check out, the Clift provided a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I write this letter to tripadvisor users to sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>We have stayed in this otel -- days and can sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Ashley Lamy, wedding coordinator, was enthusia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>The stay was good except for the mixture of sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Very nice place, very clean, and great staff. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>I was a little dubious about the reviews poste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>My first time staying and the experience could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Just back from - wonderful days in NYC! The lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>We took our daughter here to celebrate her --t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>We recently stayed - nights at this hotel and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>I booked a room in this hotel for - nights (Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>This hotel has it all , by far the best hotel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>My family of four (two youngish kids included)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Beautiful hotel, much more interesting locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>The name implied to me that this hotel would b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>My partner and I recently spent six nights at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>I am writing this review as I sit awake in bed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Park hotel is located in Union Square and very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>I am a frequent visitor to Philadelphia and of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>General Manager Deedee DeCoito and her staff a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Spent Saturday night, Oct -- at this hotel. Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>We arrived at this hotel late at night and dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>We stayed in this hotel for - night in August ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>We stayed in the New Yorker for one night on a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>It was my boyfriends birthday and about -- of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>I've stayed at this hotel in the past mostly d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Christmas Road Trip Adventure!!\\nWe were trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I have stayed here a couple of times before wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>We stayed here one night when attending an eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>We arrived at Hotel Valencia around -pm on a S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Me and - of my girls stayed at the hotel's Qua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description\n",
       "0    Looking for a motel in close proximity to TV t...\n",
       "1    Walking distance to Madison Square Garden and ...\n",
       "2    Visited Seattle on business. Spent - nights in...\n",
       "3    This hotel location is excellent and the rooms...\n",
       "4    This hotel is awesome I love the service Antho...\n",
       "5    Rooms, concierge services and party scene were...\n",
       "6    What a pleasant place to stay!\\nThe hotel is b...\n",
       "7    I booked out the same day I arrived. It cost m...\n",
       "8    Unlike some hotels that grimace when you show ...\n",
       "9    Hotel Sorella for my birthday. I absolutely lo...\n",
       "10   I had a very comfortable stay at Baymont. It w...\n",
       "11   This hotel is a keeper! First, you get a full ...\n",
       "12   Really nice lobby, with free coffee, water, co...\n",
       "13   There's a reason why so many of the previous r...\n",
       "14   Great location, close to Times Square and so m...\n",
       "15   We booked the Hampton for one night based on T...\n",
       "16   I stayed here with my girlfriend who was atten...\n",
       "17   From the location to service to amenities, thi...\n",
       "18   my work sent me down to jacksonville - times t...\n",
       "19   Stayed here for two nights while I visited DC ...\n",
       "20   This was my first visit to this property. To b...\n",
       "21   We thoroughly enjoyed our stay here. Close to ...\n",
       "22   Can't say enough about our recent stay at Hote...\n",
       "23   There are experiences in life that you embrace...\n",
       "24   Reserved a King Suite at the Blackstone thinki...\n",
       "25   This is not your typical Fairfield Inn archite...\n",
       "26   This is the best place to stay in downtown Den...\n",
       "27   This is - min away from Times Square, Central ...\n",
       "28   Check in to check out, the Clift provided a fe...\n",
       "29   I write this letter to tripadvisor users to sa...\n",
       "..                                                 ...\n",
       "970  We have stayed in this otel -- days and can sa...\n",
       "971  Ashley Lamy, wedding coordinator, was enthusia...\n",
       "972  The stay was good except for the mixture of sm...\n",
       "973  Very nice place, very clean, and great staff. ...\n",
       "974  I was a little dubious about the reviews poste...\n",
       "975  My first time staying and the experience could...\n",
       "976  Just back from - wonderful days in NYC! The lo...\n",
       "977  We took our daughter here to celebrate her --t...\n",
       "978  We recently stayed - nights at this hotel and ...\n",
       "979  I booked a room in this hotel for - nights (Ma...\n",
       "980  This hotel has it all , by far the best hotel ...\n",
       "981  My family of four (two youngish kids included)...\n",
       "982  Beautiful hotel, much more interesting locatio...\n",
       "983  The name implied to me that this hotel would b...\n",
       "984  My partner and I recently spent six nights at ...\n",
       "985  I am writing this review as I sit awake in bed...\n",
       "986  Park hotel is located in Union Square and very...\n",
       "987  I am a frequent visitor to Philadelphia and of...\n",
       "988  General Manager Deedee DeCoito and her staff a...\n",
       "989  Spent Saturday night, Oct -- at this hotel. Gr...\n",
       "990  We arrived at this hotel late at night and dec...\n",
       "991  We stayed in this hotel for - night in August ...\n",
       "992  We stayed in the New Yorker for one night on a...\n",
       "993  It was my boyfriends birthday and about -- of ...\n",
       "994  I've stayed at this hotel in the past mostly d...\n",
       "995  Christmas Road Trip Adventure!!\\nWe were trave...\n",
       "996  I have stayed here a couple of times before wi...\n",
       "997  We stayed here one night when attending an eve...\n",
       "998  We arrived at Hotel Valencia around -pm on a S...\n",
       "999  Me and - of my girls stayed at the hotel's Qua...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pool', 'spa', 'wi-fi', 'gymnasium', 'gym', 'internet', 'ample',\n",
       "       'parking', 'wireless', 'broken'], dtype='<U9')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facility = np.genfromtxt('Corpus_per_aspect/facility_aspect',dtype='str')\n",
    "location = np.genfromtxt('Corpus_per_aspect/location_aspect',dtype='str')\n",
    "value = np.genfromtxt('Corpus_per_aspect/value_aspect',dtype='str')\n",
    "service = np.genfromtxt('Corpus_per_aspect/service_aspect',dtype='str')\n",
    "meal = np.genfromtxt('Corpus_per_aspect/meal_aspect',dtype='str')\n",
    "room = np.genfromtxt('Corpus_per_aspect/room_aspect',dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "file = open(\"datatraining_sentiment_aspects.txt\",\"w\")\n",
    "a = 0\n",
    "for a in range(0,1000):\n",
    "    data = X[a,0]\n",
    "    blob = TextBlob(data)\n",
    "    doc = nlp(X[a,0])\n",
    "    polarity = [0,0,0,0,0,0]\n",
    "    blob = blob.correct()\n",
    "    for sentence in blob.sentences:\n",
    "        pol_val = sentence.sentiment.polarity\n",
    "        sentence = repr(sentence)\n",
    "        doc = nlp(sentence)\n",
    "        for token in doc:\n",
    "            if (token.lemma_ in facility):\n",
    "                polarity[0] += pol_val\n",
    "            if (token.lemma_ in location):\n",
    "                polarity[1] += pol_val\n",
    "            if (token.lemma_ in value):\n",
    "                polarity[2] += pol_val\n",
    "            if (token.lemma_ in service):\n",
    "                polarity[3] += pol_val\n",
    "            if (token.lemma_ in meal):\n",
    "                polarity[4] += pol_val\n",
    "            if (token.lemma_ in room):\n",
    "                polarity[5] += pol_val\n",
    "\n",
    "    if (polarity[0] > 0):\n",
    "        file.write(\"positive\")\n",
    "    elif (polarity[0] < 0):\n",
    "        file.write(\"negative\")\n",
    "    else:\n",
    "        file.write(\"neutral\")\n",
    "    file.write(\" \")\n",
    "    if (polarity[1] > 0):\n",
    "        file.write(\"positive\")\n",
    "    elif (polarity[1] < 0):\n",
    "        file.write(\"negative\")\n",
    "    else:\n",
    "        file.write(\"neutral\")\n",
    "    file.write(\" \")\n",
    "    if (polarity[2] > 0):\n",
    "        file.write(\"positive\")\n",
    "    elif (polarity[2] < 0):\n",
    "        file.write(\"negative\")\n",
    "    else:\n",
    "        file.write(\"neutral\")\n",
    "    file.write(\" \")\n",
    "    if (polarity[3] > 0):\n",
    "        file.write(\"positive\")\n",
    "    elif (polarity[3] < 0):\n",
    "        file.write(\"negative\")\n",
    "    else:\n",
    "        file.write(\"neutral\")\n",
    "    file.write(\" \")\n",
    "    if (polarity[4] > 0):\n",
    "        file.write(\"positive\")\n",
    "    elif (polarity[4] < 0):\n",
    "        file.write(\"negative\")\n",
    "    else:\n",
    "        file.write(\"neutral\")\n",
    "    file.write(\" \")\n",
    "    if (polarity[5] > 0):\n",
    "        file.write(\"positive\")\n",
    "    elif (polarity[5] < 0):\n",
    "        file.write(\"negative\")\n",
    "    else:\n",
    "        file.write(\"neutral\")\n",
    "    file.write(\"\\n\")\n",
    "    a += 1\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['neutral', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "        'positive'],\n",
       "       ['negative', 'positive', 'positive', 'positive', 'positive',\n",
       "        'positive'],\n",
       "       ['positive', 'negative', 'neutral', 'neutral', 'neutral',\n",
       "        'positive'],\n",
       "       ...,\n",
       "       ['positive', 'positive', 'positive', 'neutral', 'positive',\n",
       "        'positive'],\n",
       "       ['neutral', 'neutral', 'neutral', 'positive', 'positive',\n",
       "        'positive'],\n",
       "       ['neutral', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "        'positive']], dtype='<U8')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.genfromtxt('datatraining_sentiment_aspects.txt',dtype='str')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(0,100):\n",
    "    print(noun_list[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_widget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             subprocess.call([find_binary('gs', binary_names=['gswin32c.exe', 'gswin64c.exe'], env_vars=['PATH'], verbose=False)] +\n\u001b[0m\u001b[0;32m    731\u001b[0m                             \u001b[1;34m'-q -dEPSCrop -sDEVICE=png16m -r90 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -dSAFER -dBATCH -dNOPAUSE -sOutputFile={0:} {1:}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m                             .format(out_path, in_path).split())\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    602\u001b[0m                 binary_names=None, url=None, verbose=False):\n\u001b[0;32m    603\u001b[0m     return next(find_binary_iter(name, path_to_bin, env_vars, searchpath,\n\u001b[1;32m--> 604\u001b[1;33m                                  binary_names, url, verbose))\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m def find_jar_iter(name_pattern, path_to_jar=None, env_vars=(),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \"\"\"\n\u001b[0;32m    597\u001b[0m     for file in  find_file_iter(path_to_bin or name, env_vars, searchpath, binary_names,\n\u001b[1;32m--> 598\u001b[1;33m                      url, verbose):\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    567\u001b[0m                         (filename, url))\n\u001b[0;32m    568\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'='\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n==========================================================================="
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('Stayed', 'VBN'), ('here', 'RB'), ('with', 'IN'), ('husband', 'NN'), ('and', 'CC'), ('sons', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('way', 'NN'), ('to', 'TO'), ('an', 'DT'), Tree('PERSON', [('Alaska', 'NNP'), ('Cruise', 'NNP')]), ('.', '.'), ('We', 'PRP'), ('all', 'DT'), ('loved', 'VBD'), ('the', 'DT'), ('hotel', 'NN'), (',', ','), ('great', 'JJ'), ('experience', 'NN'), ('.', '.'), ('Ask', 'NNP'), ('for', 'IN'), ('a', 'DT'), ('room', 'NN'), ('on', 'IN'), ('the', 'DT'), Tree('GPE', [('North', 'NNP')]), ('tower', 'NN'), (',', ','), ('facing', 'VBG'), ('north', 'JJ'), ('west', 'NN'), ('for', 'IN'), ('the', 'DT'), ('best', 'JJS'), ('views', 'NNS'), ('.', '.'), ('We', 'PRP'), ('had', 'VBD'), ('a', 'DT'), ('high', 'JJ'), ('floor', 'NN'), (',', ','), ('with', 'IN'), ('a', 'DT'), ('stunning', 'JJ'), ('view', 'NN'), ('of', 'IN'), ('the', 'DT'), ('needle', 'NN'), (',', ','), ('the', 'DT'), ('city', 'NN'), (',', ','), ('and', 'CC'), ('even', 'RB'), ('the', 'DT'), ('cruise', 'NN'), ('ships', 'VBZ'), ('!', '.'), ('We', 'PRP'), ('ordered', 'VBD'), ('room', 'NN'), ('service', 'NN'), ('for', 'IN'), ('dinner', 'NN'), ('so', 'IN'), ('we', 'PRP'), ('could', 'MD'), ('enjoy', 'VB'), ('the', 'DT'), ('perfect', 'JJ'), ('views', 'NNS'), ('.', '.'), Tree('PERSON', [('Room', 'NNP')]), ('service', 'NN'), ('dinners', 'NNS'), ('were', 'VBD'), ('delicious', 'JJ'), (',', ','), ('too', 'RB'), ('!', '.'), ('You', 'PRP'), ('are', 'VBP'), ('in', 'IN'), ('a', 'DT'), ('perfect', 'JJ'), ('spot', 'NN'), ('to', 'TO'), ('walk', 'VB'), ('everywhere', 'RB'), (',', ','), ('so', 'RB'), ('enjoy', 'VB'), ('the', 'DT'), ('city', 'NN'), ('.', '.'), ('Almost', 'RBS'), ('forgot-', 'JJ'), ('Heavenly', 'NNP'), ('beds', 'NNS'), ('were', 'VBD'), ('heavenly', 'RB'), (',', ','), ('too', 'RB'), ('!', '.')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "path_to_gs = \"C:\\Program Files\\gs\\gs9.25\\bin\"\n",
    "os.environ['PATH'] += os.pathsep + path_to_gs\n",
    "\n",
    "tokens = nltk.word_tokenize(X[3,0])\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alaska GPE\n",
      "North GPE\n",
      "Stayed stay VERB VBN ROOT Xxxxx True False\n",
      "here here ADV RB advmod xxxx True True\n",
      "with with ADP IN prep xxxx True True\n",
      "husband husband NOUN NN pobj xxxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "sons son NOUN NNS conj xxxx True False\n",
      "on on ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "way way NOUN NN pobj xxx True False\n",
      "to to ADP IN prep xx True True\n",
      "an an DET DT det xx True True\n",
      "Alaska alaska PROPN NNP compound Xxxxx True False\n",
      "Cruise cruise PROPN NNP pobj Xxxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "We -PRON- PRON PRP nsubj Xx True False\n",
      "all all DET DT appos xxx True True\n",
      "loved love VERB VBD ROOT xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "hotel hotel NOUN NN dobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "great great ADJ JJ amod xxxx True False\n",
      "experience experience NOUN NN appos xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "Ask ask VERB VB ROOT Xxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "a a DET DT det x True True\n",
      "room room NOUN NN pobj xxxx True False\n",
      "on on ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "North north PROPN NNP compound Xxxxx True False\n",
      "tower tower NOUN NN pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "facing face VERB VBG advcl xxxx True False\n",
      "north north ADV RB compound xxxx True False\n",
      "west west NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "the the DET DT det xxx True True\n",
      "best good ADJ JJS amod xxxx True False\n",
      "views view NOUN NNS pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "We -PRON- PRON PRP nsubj Xx True False\n",
      "had have VERB VBD ROOT xxx True True\n",
      "a a DET DT det x True True\n",
      "high high ADJ JJ amod xxxx True False\n",
      "floor floor NOUN NN dobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "with with ADP IN prep xxxx True True\n",
      "a a DET DT det x True True\n",
      "stunning stunning ADJ JJ amod xxxx True False\n",
      "view view NOUN NN pobj xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "needle needle NOUN NN pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "the the DET DT det xxx True True\n",
      "city city NOUN NN conj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "and and CCONJ CC cc xxx True True\n",
      "even even ADV RB advmod xxxx True True\n",
      "the the DET DT det xxx True True\n",
      "cruise cruise NOUN NN compound xxxx True False\n",
      "ships ship NOUN NNS conj xxxx True False\n",
      "! ! PUNCT . punct ! False False\n",
      "We -PRON- PRON PRP nsubj Xx True False\n",
      "ordered order VERB VBD ROOT xxxx True False\n",
      "room room NOUN NN compound xxxx True False\n",
      "service service NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "dinner dinner NOUN NN pobj xxxx True False\n",
      "so so ADP IN mark xx True True\n",
      "we -PRON- PRON PRP nsubj xx True True\n",
      "could could VERB MD aux xxxx True True\n",
      "enjoy enjoy VERB VB advcl xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "perfect perfect ADJ JJ amod xxxx True False\n",
      "views view NOUN NNS dobj xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "Room room NOUN NN compound Xxxx True False\n",
      "service service NOUN NN compound xxxx True False\n",
      "dinners dinner NOUN NNS nsubj xxxx True False\n",
      "were be VERB VBD ROOT xxxx True True\n",
      "delicious delicious ADJ JJ acomp xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "too too ADV RB advmod xxx True True\n",
      "! ! PUNCT . punct ! False False\n",
      "You -PRON- PRON PRP nsubj Xxx True False\n",
      "are be VERB VBP ccomp xxx True True\n",
      "in in ADP IN prep xx True True\n",
      "a a DET DT det x True True\n",
      "perfect perfect ADJ JJ amod xxxx True False\n",
      "spot spot NOUN NN pobj xxxx True False\n",
      "to to PART TO aux xx True True\n",
      "walk walk VERB VB advcl xxxx True False\n",
      "everywhere everywhere ADV RB advmod xxxx True True\n",
      ", , PUNCT , punct , False False\n",
      "so so ADV RB advmod xx True True\n",
      "enjoy enjoy VERB VB ROOT xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "city city NOUN NN dobj xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "Almost almost ADV RB advmod Xxxxx True False\n",
      "forgot- forgot- ADJ JJ ROOT xxxx- False False\n",
      "Heavenly heavenly PROPN NNP amod Xxxxx True False\n",
      "beds bed NOUN NNS nsubj xxxx True False\n",
      "were be VERB VBD ROOT xxxx True True\n",
      "heavenly heavenly ADV RB advmod xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "too too ADV RB advmod xxx True True\n",
      "! ! PUNCT . punct ! False False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "a = 0\n",
    "doc = nlp(X[3,0])\n",
    "if (a <= 2):\n",
    "    for entity in doc.ents:\n",
    "        print(entity.text, entity.label_)\n",
    "\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "              token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "classifier_label = ['Happy','Not Happy']\n",
    "count_vect = CountVectorizer(stop_words=\"english\")\n",
    "train_counts = count_vect.fit_transform(X[:,0])\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(train_counts)\n",
    "train_tf = tf_transformer.transform(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing the learning method with some input\n",
    "test = ['Selamat! Anda mendapatkan uang sebesar 100 juta rupiah. Untuk informasi lebih lanjut, ' + \n",
    "        'silakan hubungi nomor berikut +628654321234', #spam\n",
    "        'Ma, boleh transfer pulsa dulu ke nomor ini? Aku belum bisa isi ulang masih di kampus dulu sekarang', #ham\n",
    "        'aaa', #ham\n",
    "        'Transfer saldonya ke rekening ini ya 542 098 7543', #spam\n",
    "        'Tolong kirim fotocopy KTP dan KK ke email berikut', #ham\n",
    "        'Registrasi kartumu segera sebelum 1 Oktober 2019', #ham\n",
    "        'Halo, ada yang bisa dibantu?', #ham\n",
    "       ]\n",
    "test_count = count_vect.transform(test)\n",
    "test_tfidf = tf_transformer.transform(test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier_NB = MultinomialNB().fit(train_tf,train.label)\n",
    "\n",
    "test_predict = classifier_NB.predict(test_tfidf)\n",
    "\n",
    "for doc, category in zip(test, test_predict):\n",
    "    print('%r => %s' % (doc, classifier_label[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_RF = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0).fit(train_tf,train.label)\n",
    "\n",
    "test_predict = classifier_RF.predict(test_tfidf)\n",
    "\n",
    "for doc, category in zip(test, test_predict):\n",
    "    print('%r => %s' % (doc, classifier_label[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifier_SVC = LinearSVC().fit(train_tf,train.label)\n",
    "\n",
    "test_predict = classifier_SVC.predict(test_tfidf)\n",
    "\n",
    "for doc, category in zip(test, test_predict):\n",
    "    print('%r => %s' % (doc, classifier_label[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "There are 3 algorithms used in this program:\n",
    "  - Multinomial Naive Bayes Classifier\n",
    "  - Random Forest Classifier\n",
    "  - Linear SVM (Support Vector Classifier)\n",
    "  \n",
    "Comparing the 3 algorithms, Multinomial Naive Bayes achieves 85.7% accuracy (6/7 correct), Random Forest with 71.4% accuracy (5/7 correct), and Linear SVM with 57.1% accuracy (4/7 correct).\n",
    "\n",
    "This is caused by the nature of each algorithm. Multinomial Naive Bayes matches the words from the test case to the word appearances from the tokenized word bank, when the words match the categories, the chances of the test case entering the matching category increases.\n",
    "Random Forest Classifier uses multiple decision trees trained at the subsets of the data, with a random replacement in the data sets in every iteration.\n",
    "Linear SVM divide 2 classifier (spam and ham) with linear equation line in a vector space, but some data in a classification probably isn't in the area of its cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
